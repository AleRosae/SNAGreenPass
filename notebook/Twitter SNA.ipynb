{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Twitter SNA.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPNEkLeY87X9gsRJ9nblhV7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"yBBguQr29pya"},"source":["Intall Tweepy, import libraries and mount the drive. Then you have to log in with your Twitter API credentials."]},{"cell_type":"code","metadata":{"id":"2oOT2l0oAvsS"},"source":["%%capture\n","!pip install tweepy\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P1r5JrKnhNuX"},"source":["import os\n","import tweepy as tw\n","import pandas as pd\n","import json\n","from datetime import datetime, timedelta\n","import time\n","import networkx as nx\n","import re\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y1-jQQ_jj0Hg"},"source":["auth = tw.OAuthHandler(\"\", \"\")\n","auth.set_access_token(\"\", \"\")\n","api = tw.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Rz7vWbkAwvBU"},"source":["We collect the data from Twitter using the Tweepy library. Three queries related to teh Green Pass discussion are made. Since Twitter's API are limited, we can only collect posts that are max 7 days old. \n","Notice that this process may take a while. To avoid disconnected runtimes with Colab, it is suggested to run this locally (even running this notebook with a [local runtime](https://research.google.com/colaboratory/local-runtimes.html)"]},{"cell_type":"code","metadata":{"id":"kO7UiNAXj3DB","colab":{"base_uri":"https://localhost:8080/"},"outputId":"5d4d3a3a-e758-45bf-e8ce-1694f8b1c4da"},"source":["#this function scrap tweets using the Twitter api and creates a pandas dataframe to better manage the data\n","tweet_dict = {}\n","lista_key = [\"#nogreepass\", \"#GreenpassObbligatorio\"]\n","\n","for keyword in lista_key:\n","  try:\n","    tweets = tw.Cursor(api.search, q=keyword, result_type=\"mixed\", lang='it', exclude_mentions=False).items()\n","    for tweet in tweets:\n","      tweet_dict[tweet.id_str] = {}\n","      tweet_dict[tweet.id_str][\"tweet_id\"] = tweet.id_str\n","      tweet_dict[tweet.id_str][\"text\"] = tweet.text\n","      tweet_dict[tweet.id_str][\"date\"] = tweet.created_at\n","      tweet_dict[tweet.id_str][\"user\"] = tweet.user.id_str\n","      tweet_dict[tweet.id_str][\"user_name\"] = tweet.user.name\n","      tweet_dict[tweet.id_str][\"user_verified\"] = tweet.user.verified\n","      tweet_dict[tweet.id_str][\"user_description\"] = tweet.user.description\n","      tweet_dict[tweet.id_str][\"in_reply_to_user\"] = tweet.in_reply_to_user_id_str\n","      tweet_dict[tweet.id_str][\"in_reply_to_tweet\"] = tweet.in_reply_to_status_id_str\n","      tweet_dict[tweet.id_str][\"in_reply_to_user_name\"] = tweet.in_reply_to_screen_name\n","      if len (tweet.entities[\"user_mentions\"]) > 0:\n","        tweet_dict[tweet.id_str][\"user_mentions\"] = tweet.entities[\"user_mentions\"][0][\"id\"]\n","      if len( tweet.entities[\"urls\"]) > 0:\n","        tweet_dict[tweet.id_str][\"links\"] = tweet.entities[\"urls\"][0][\"expanded_url\"]\n","      else: \n","        tweet_dict[tweet.id_str][\"links\"] = tweet.entities[\"urls\"]\n","    print(len(tweet_dict.keys()))\n","  except tw.TweepError: \n","    print(\"error\")\n","    time.sleep(60)\n","\n","date = datetime.today().date()\n","df = pd.DataFrame(data=tweet_dict)\n","df = df.transpose()\n","filename = \"Twitter_GP_\"+ str(date)\n","df.to_csv(\"/content/drive/MyDrive/Colab Notebooks/Twitter SNA/\"+filename+\".csv\")\n","df"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Rate limit reached. Sleeping for: 130\n","Rate limit reached. Sleeping for: 849\n","Rate limit reached. Sleeping for: 846\n","Rate limit reached. Sleeping for: 846\n"]},{"output_type":"stream","name":"stdout","text":["10446\n"]},{"output_type":"stream","name":"stderr","text":["Rate limit reached. Sleeping for: 847\n"]},{"output_type":"stream","name":"stdout","text":["12845\n"]},{"output_type":"stream","name":"stderr","text":["Rate limit reached. Sleeping for: 849\n","Rate limit reached. Sleeping for: 847\n","Rate limit reached. Sleeping for: 850\n","Rate limit reached. Sleeping for: 848\n","Rate limit reached. Sleeping for: 850\n","Rate limit reached. Sleeping for: 848\n","Rate limit reached. Sleeping for: 848\n","Rate limit reached. Sleeping for: 849\n","Rate limit reached. Sleeping for: 849\n","Rate limit reached. Sleeping for: 847\n","Rate limit reached. Sleeping for: 849\n","Rate limit reached. Sleeping for: 849\n","Rate limit reached. Sleeping for: 848\n","Rate limit reached. Sleeping for: 849\n","Rate limit reached. Sleeping for: 849\n","Rate limit reached. Sleeping for: 849\n","Rate limit reached. Sleeping for: 846\n","Rate limit reached. Sleeping for: 850\n","Rate limit reached. Sleeping for: 849\n","Rate limit reached. Sleeping for: 849\n","Rate limit reached. Sleeping for: 850\n","Rate limit reached. Sleeping for: 850\n","Rate limit reached. Sleeping for: 847\n","Rate limit reached. Sleeping for: 850\n","Rate limit reached. Sleeping for: 851\n","Rate limit reached. Sleeping for: 848\n","Rate limit reached. Sleeping for: 851\n","Rate limit reached. Sleeping for: 851\n","Rate limit reached. Sleeping for: 845\n","Rate limit reached. Sleeping for: 852\n","Rate limit reached. Sleeping for: 851\n","Rate limit reached. Sleeping for: 852\n","Rate limit reached. Sleeping for: 851\n","Rate limit reached. Sleeping for: 851\n","Rate limit reached. Sleeping for: 852\n","Rate limit reached. Sleeping for: 850\n","Rate limit reached. Sleeping for: 852\n","Rate limit reached. Sleeping for: 843\n","Rate limit reached. Sleeping for: 849\n"]}]},{"cell_type":"markdown","metadata":{"id":"TwULG-3CxJ9f"},"source":["By runnin the previous cell on different days  we can create multiple dataframes that need to be merged togther. \n","We use the Networkx library to create a set of edges that represent the connection between users replies. Since the matplot library is not able to handle this number of connections, we export the edges list into a format more suitable for Gephi. "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":796},"id":"Duxe6g0vf_M8","executionInfo":{"status":"ok","timestamp":1635260798088,"user_tz":-120,"elapsed":966,"user":{"displayName":"Alessandro Rosa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GikpMMlbMY8QHKmcLSBZSQWc-Yy-5rzUsQpXm37=s64","userId":"09715574712161097240"}},"outputId":"278ea50a-5899-4255-e8de-e3199bdb42fe"},"source":["#df_10 = pd.read_json(\"/content/drive/MyDrive/Colab Notebooks/Twitter SNA/Twitter_GP_2021-10-10.json\")\n","df_17 = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Twitter SNA/Twitter_GP_2021-10-17-safe_with_mentions.csv\", lineterminator='\\n')\n","df_17 = df_17.drop([\"Unnamed: 0\",\"Unnamed: 0.1\", \"Unnamed: 0.1.1\",\"Unnamed: 0.1.1.1\"], axis=1)\n","df_24 = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Twitter SNA/Twitter_GP_2021-10-24-safe.csv\", lineterminator='\\n')\n","df = pd.concat([df_17, df_24])\n","#df = df[(df[\"user_mentions\"].isnull()) & df[\"in_reply_to_tweet\"].isnull()]\n","df\n","\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>date</th>\n","      <th>user</th>\n","      <th>user_name</th>\n","      <th>user_verified</th>\n","      <th>user_description</th>\n","      <th>in_reply_to_user</th>\n","      <th>in_reply_to_tweet</th>\n","      <th>in_reply_to_user_name</th>\n","      <th>links</th>\n","      <th>tweet_id</th>\n","      <th>user_mentions</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Criminali. Senza alcun tipo di giustificazione...</td>\n","      <td>2021-10-09 18:55:22</td>\n","      <td>963073442</td>\n","      <td>Chiara Appendino</td>\n","      <td>True</td>\n","      <td>Sindaca di Torino \\ Mayor of Turin</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>https://twitter.com/i/web/status/1446912188657...</td>\n","      <td>1446912188657057794</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Un branco di fascisti assalta un sindacato. Qu...</td>\n","      <td>2021-10-09 18:48:01</td>\n","      <td>232534560</td>\n","      <td>Fabio Alisei</td>\n","      <td>True</td>\n","      <td>Sono quello nella foto ma senza photoshop.</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>[]</td>\n","      <td>1446910335902957578</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>#nogreepass. Sono state arrestate 12 persone c...</td>\n","      <td>2021-10-10 08:58:20</td>\n","      <td>5893702</td>\n","      <td>Sky tg24</td>\n","      <td>True</td>\n","      <td>News, video, fotogallery e la diretta web 24 o...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>https://twitter.com/i/web/status/1447124327380...</td>\n","      <td>1447124327380439042</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>@Cartabellotta In confronto a lei #StefanoPuzz...</td>\n","      <td>2021-10-17 13:10:58</td>\n","      <td>287566348</td>\n","      <td>Ebby</td>\n","      <td>False</td>\n","      <td>Giuro Solennemente di non avere buone intenzioni.</td>\n","      <td>231902290.0</td>\n","      <td>1.449658e+18</td>\n","      <td>Cartabellotta</td>\n","      <td>https://twitter.com/i/web/status/1449724621087...</td>\n","      <td>1449724621087985668</td>\n","      <td>2.319023e+08</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>RT @matteo_rivi: Non so più come dirlo: Puzzer...</td>\n","      <td>2021-10-17 13:09:16</td>\n","      <td>1420711554270511104</td>\n","      <td>Deodato RIBEIRA</td>\n","      <td>False</td>\n","      <td>SRV 4ever ( ok, per i più giovani..SRV means S...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>[]</td>\n","      <td>1449724193210253312</td>\n","      <td>1.254793e+18</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>14433</th>\n","      <td>Domani, 13esimo sabato consecutivo di proteste...</td>\n","      <td>2021-10-15 18:00:00</td>\n","      <td>3775808595</td>\n","      <td>Mi-Tomorrow</td>\n","      <td>False</td>\n","      <td>© @pradivio • L’unico giornale gratuito del po...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>https://twitter.com/i/web/status/1449072580967...</td>\n","      <td>1449072580967604224</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>14434</th>\n","      <td>Che figura di merda\\n#GreenpassObbligatorio #g...</td>\n","      <td>2021-10-15 17:59:32</td>\n","      <td>1128224182750384128</td>\n","      <td>Claudio Binnella</td>\n","      <td>False</td>\n","      <td>Se svolti a sinistra vai a sbattere</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>https://twitter.com/PeterSweden7/status/144901...</td>\n","      <td>1449072465112674304</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>14435</th>\n","      <td>Sono aumentati i certificati di malattia. \\nMa...</td>\n","      <td>2021-10-15 17:59:24</td>\n","      <td>79211525</td>\n","      <td>Kattoliko Pensiero</td>\n","      <td>False</td>\n","      <td>I am an Italian Catholic, husband, teacher, bl...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>[]</td>\n","      <td>1449072430031544322</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>14436</th>\n","      <td>RT @CoGiafra: Perché non viene organizzata una...</td>\n","      <td>2021-10-15 17:56:58</td>\n","      <td>2754565029</td>\n","      <td>Rosad24</td>\n","      <td>False</td>\n","      <td>Sturm und Drang</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>[]</td>\n","      <td>1449071816132153354</td>\n","      <td>2.730966e+09</td>\n","    </tr>\n","    <tr>\n","      <th>14437</th>\n","      <td>RT @longagnani: #Bologna #greenpassday 15 otto...</td>\n","      <td>2021-10-15 17:56:05</td>\n","      <td>345219705</td>\n","      <td>lasedicesimadose</td>\n","      <td>False</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>[]</td>\n","      <td>1449071596044496896</td>\n","      <td>3.193426e+08</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>90936 rows × 12 columns</p>\n","</div>"],"text/plain":["                                                    text  ... user_mentions\n","0      Criminali. Senza alcun tipo di giustificazione...  ...           NaN\n","1      Un branco di fascisti assalta un sindacato. Qu...  ...           NaN\n","2      #nogreepass. Sono state arrestate 12 persone c...  ...           NaN\n","3      @Cartabellotta In confronto a lei #StefanoPuzz...  ...  2.319023e+08\n","4      RT @matteo_rivi: Non so più come dirlo: Puzzer...  ...  1.254793e+18\n","...                                                  ...  ...           ...\n","14433  Domani, 13esimo sabato consecutivo di proteste...  ...           NaN\n","14434  Che figura di merda\\n#GreenpassObbligatorio #g...  ...           NaN\n","14435  Sono aumentati i certificati di malattia. \\nMa...  ...           NaN\n","14436  RT @CoGiafra: Perché non viene organizzata una...  ...  2.730966e+09\n","14437  RT @longagnani: #Bologna #greenpassday 15 otto...  ...  3.193426e+08\n","\n","[90936 rows x 12 columns]"]},"metadata":{},"execution_count":95}]},{"cell_type":"code","metadata":{"id":"Yk_J5D0O6rUh"},"source":["import networkx as nx\n","\n","df_self = df[df[\"in_reply_to_user\"].isnull()]\n","df_dir= df[df[\"in_reply_to_user\"].notnull()]\n","df_men= df[df[\"user_mentions\"].notnull()]\n","\n","G = nx.MultiGraph()\n","for index, row in df_self.iterrows():\n","    G.add_edge(int(row[\"user\"]), int(row[\"user\"]))\n","\n","for index, row in df_dir.iterrows():\n","  G.add_edge(int(row[\"user\"]), int(row[\"in_reply_to_user\"]))\n","\n","for index, row in df_men.iterrows():\n","  G.add_edge(int(row[\"user\"]), int(row[\"user_mentions\"]))\n","\n","\n","nx.write_edgelist(G, \"/content/drive/MyDrive/Colab Notebooks/Twitter SNA/gephi_data/edges_final_17_24.csv\", delimiter=',', data=False)\n"],"execution_count":null,"outputs":[]}]}